{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "735e184d",
      "metadata": {
        "id": "735e184d"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade --force-reinstall --no-deps --no-cache-dir unsloth unsloth_zoo\n",
        "# !pip install --upgrade unsloth\n",
        "!pip install unsloth\n",
        "# Install the missing 'addict' package\n",
        "!pip install addict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cái này dùng để test nha mấy bồ :>>**"
      ],
      "metadata": {
        "id": "RFG9Tc8YPiAT"
      },
      "id": "RFG9Tc8YPiAT"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "183966a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "183966a4",
        "outputId": "fd613da8-5110-46b4-c959-dc9e201bd686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: addict in /usr/local/lib/python3.12/dist-packages (2.4.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: WARNING `trust_remote_code` is True.\n",
            "Are you certain you want to do remote code execution?\n",
            "==((====))==  Unsloth 2025.12.1: Fast Deepseekocr patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DeepseekOCRForCausalLM were not initialized from the model checkpoint at ./deepseek_ocr and are newly initialized: ['model.vision_model.embeddings.position_ids']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====================\n",
            "BASE:  torch.Size([1, 256, 1280])\n",
            "PATCHES:  torch.Size([3, 100, 1280])\n",
            "=====================\n",
            "Tiếp tục nhận rằng, cái mỏ hình huy động vốn đầu tư. Tập trung khai  \n",
            "thái cái nguồn vốn cho ngân sách. Tổng kết quả trình có phản hại  \n",
            "doanh nghiệp nhà nước và việc tổ chức tập xếp lại doanh nghiệp nhà  \n",
            "nước. Trên khai quyết định của TP về một số chính sách vừa đủ  \n",
            "tốt với cái dài án có vốn đầu tư nước ngoài. Ra sát lại chương  \n",
            "trình hồn nhập hình tế của TP. Về văn hóa - xã hội: dạy môn  \n",
            "xã hội hóa, phát triển xã hội học tập, viu tiên đầu tư ngân  \n",
            "sách cho giáo dục - đào tạo.\n",
            "===============save results:===============\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "image: 0it [00:00, ?it/s]\n",
            "other: 0it [00:00, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastVisionModel\n",
        "import torch\n",
        "from transformers import AutoModel\n",
        "import os\n",
        "os.environ[\"UNSLOTH_WARN_UNINITIALIZED\"] = '0'\n",
        "\n",
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(\"unsloth/DeepSeek-OCR\", local_dir = \"deepseek_ocr\")\n",
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "    \"./deepseek_ocr\",\n",
        "    load_in_4bit = False, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
        "    auto_model = AutoModel,\n",
        "    trust_remote_code = True,\n",
        "    unsloth_force_compile = True,\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
        ")\n",
        "# Load ảnh\n",
        "prompt = \"<image>\\nFree OCR. \"\n",
        "image_file = \"ViHandwrittenOCR/UIT_HWDB_paragraph/test_data/251/5.jpg\"\n",
        "output_path = 'output'\n",
        "res = model.infer(tokenizer, prompt=prompt, image_file=image_file, output_path = output_path, base_size = 1024, image_size = 640, crop_mode=True, save_results = True, test_compress = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finetuning go go brh**"
      ],
      "metadata": {
        "id": "Dxzs5u0fPrRZ"
      },
      "id": "Dxzs5u0fPrRZ"
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastVisionModel # FastLanguageModel for LLMs\n",
        "import torch\n",
        "from transformers import AutoModel\n",
        "import os\n",
        "os.environ[\"UNSLOTH_WARN_UNINITIALIZED\"] = '0'\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Qwen3-VL-8B-Instruct-bnb-4bit\", # Qwen 3 vision support\n",
        "    \"unsloth/Qwen3-VL-8B-Thinking-bnb-4bit\",\n",
        "    \"unsloth/Qwen3-VL-32B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Qwen3-VL-32B-Thinking-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastVisionModel.from_pretrained(\n",
        "    \"./deepseek_ocr\",\n",
        "    load_in_4bit = False, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
        "    auto_model = AutoModel,\n",
        "    trust_remote_code=True,\n",
        "    unsloth_force_compile=True,\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
        ")"
      ],
      "metadata": {
        "id": "qY6h4GiSP5BH",
        "outputId": "a2355d5d-5b99-46de-8c22-596e9f458200",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "qY6h4GiSP5BH",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: WARNING `trust_remote_code` is True.\n",
            "Are you certain you want to do remote code execution?\n",
            "==((====))==  Unsloth 2025.12.1: Fast Deepseekocr patching. Transformers: 4.57.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.1+cu128. CUDA: 7.5. CUDA Toolkit: 12.8. Triton: 3.5.1\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post2. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DeepseekOCRForCausalLM were not initialized from the model checkpoint at ./deepseek_ocr and are newly initialized: ['model.vision_model.embeddings.position_ids']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/accelerate/utils/modeling.py:1598: UserWarning: The following device_map keys do not match any submodules in the model: ['model.image_newline', 'model.view_seperator']\n",
            "  warnings.warn(\n",
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}